{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script will scrape the Hedgeye webpage and retrieve the top trending articles' information into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dataframes manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# For web scrapping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# For CSV writer\n",
    "from io import StringIO\n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/ Consts declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main url for the website\n",
    "CONST_URL = 'https://app.hedgeye.com'\n",
    "\n",
    "# Suffix for the website's main page to scrape the list of trending articles\n",
    "CONST_homepageSuffix = '/insights'\n",
    "\n",
    "# HTML class for each trending article's link\n",
    "CONST_TrendingArticlesClass = 'trending-insight'\n",
    "CONST_nbArticlesToScrape = 6\n",
    "\n",
    "# HTML classes for each needed information from each article link\n",
    "CONST_class_articleName = 'headline-link'\n",
    "CONST_class_authorPhoto = 'headshot'\n",
    "CONST_class_authorName = 'full-name'\n",
    "CONST_class_authorTwitter = 'twitter-handle'\n",
    "\n",
    "CONST_itemProp_datePublished = 'datePublished'\n",
    "CONST_itemProp_contentBody = 'articleBody'\n",
    "\n",
    "# Dataframe header containing the results\n",
    "columns = ['URL', 'ARTICLE_NAME', 'DATE_PUBLISHED', 'AUTHOR_NAME', 'AUTHOR_PHOTO_LINK', 'AUTHOR_TWITTER']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2/ Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = StringIO()\n",
    "csv_writer = writer(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the whole main webpage\n",
    "res = requests.get(CONST_URL + CONST_homepageSuffix)\n",
    "soup = BeautifulSoup(res.content,'lxml')\n",
    "\n",
    "# Get the list of trending articles from the main page\n",
    "trendingArticles = soup.find_all(\"div\", {\"class\": CONST_TrendingArticlesClass})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To loop through 'CONST_nbArticlesToScrape' articles maximum\n",
    "cptArticles = 0\n",
    "\n",
    "# Loop through each trending article\n",
    "for article in trendingArticles:\n",
    "    # Get the article URL\n",
    "    articleUrl = article.find('a').get('href')\n",
    "    \n",
    "    # Query the URL\n",
    "    resCurrentArticle = requests.get(CONST_URL + articleUrl)\n",
    "    soupCurrentArticle = BeautifulSoup(resCurrentArticle.content,'lxml')\n",
    "    \n",
    "    # Retrieve each variable\n",
    "    articleName = soupCurrentArticle.find(\"div\", {\"class\": CONST_class_articleName})\n",
    "    if (articleName is not None): articleName = articleName.find('h1', {\"itemprop\": 'name'}).getText()\n",
    "        \n",
    "    datePublished = soupCurrentArticle.find(\"time\", {\"itemprop\": CONST_itemProp_datePublished})\n",
    "    if (datePublished is not None): datePublished = datePublished.get('datetime')\n",
    "    \n",
    "    authorPhotoLink = soupCurrentArticle.find(\"div\", {\"class\": CONST_class_authorPhoto})\n",
    "    if (authorPhotoLink is not None): authorPhotoLink = authorPhotoLink.find('img').get('src')\n",
    "    \n",
    "    authorName = soupCurrentArticle.find(\"div\", {\"class\": CONST_class_authorName})\n",
    "    if (authorName is not None): authorName = authorName.getText()\n",
    "    \n",
    "    authorTwitter = soupCurrentArticle.find(\"div\", {\"class\": CONST_class_authorTwitter})\n",
    "    if (authorTwitter is not None): authorTwitter = authorTwitter.find('a').getText()\n",
    "\n",
    "    # Write the elements into a CSV writer flow\n",
    "    csv_writer.writerow((articleUrl, articleName, datePublished, authorName, authorPhotoLink, authorTwitter))\n",
    "    cptArticles = cptArticles + 1\n",
    "    if (cptArticles >= CONST_nbArticlesToScrape):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>ARTICLE_NAME</th>\n",
       "      <th>DATE_PUBLISHED</th>\n",
       "      <th>AUTHOR_NAME</th>\n",
       "      <th>AUTHOR_PHOTO_LINK</th>\n",
       "      <th>AUTHOR_TWITTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/insights/76052-webcast-replay-one-on-one-with...</td>\n",
       "      <td>WEBCAST REPLAY: One-On-One With Renowned Short...</td>\n",
       "      <td>2019-06-20T08:27:21-04:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/insights/76037-mccullough-i-want-you-to-focus...</td>\n",
       "      <td>McCullough: I Want You To Focus On 'Full Cycle...</td>\n",
       "      <td>2019-06-19T12:07:18-04:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/insights/76020-mccullough-draghi-goes-dovish-...</td>\n",
       "      <td>McCullough: Draghi Goes Dovish → It's Called '...</td>\n",
       "      <td>2019-06-18T12:54:17-04:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/insights/75992-quad-4-signs-are-everywhere</td>\n",
       "      <td>Quad 4 Signs Are Everywhere</td>\n",
       "      <td>2019-06-17T12:34:29-04:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/insights/75963-long-gold-you-re-getting-paid</td>\n",
       "      <td>Long Gold? You're Getting Paid</td>\n",
       "      <td>2019-06-14T11:48:47-04:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  /insights/76052-webcast-replay-one-on-one-with...   \n",
       "1  /insights/76037-mccullough-i-want-you-to-focus...   \n",
       "2  /insights/76020-mccullough-draghi-goes-dovish-...   \n",
       "3        /insights/75992-quad-4-signs-are-everywhere   \n",
       "4      /insights/75963-long-gold-you-re-getting-paid   \n",
       "\n",
       "                                        ARTICLE_NAME  \\\n",
       "0  WEBCAST REPLAY: One-On-One With Renowned Short...   \n",
       "1  McCullough: I Want You To Focus On 'Full Cycle...   \n",
       "2  McCullough: Draghi Goes Dovish → It's Called '...   \n",
       "3                        Quad 4 Signs Are Everywhere   \n",
       "4                     Long Gold? You're Getting Paid   \n",
       "\n",
       "              DATE_PUBLISHED  AUTHOR_NAME  AUTHOR_PHOTO_LINK  AUTHOR_TWITTER  \n",
       "0  2019-06-20T08:27:21-04:00          NaN                NaN             NaN  \n",
       "1  2019-06-19T12:07:18-04:00          NaN                NaN             NaN  \n",
       "2  2019-06-18T12:54:17-04:00          NaN                NaN             NaN  \n",
       "3  2019-06-17T12:34:29-04:00          NaN                NaN             NaN  \n",
       "4  2019-06-14T11:48:47-04:00          NaN                NaN             NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to get back to the start of the BytesIO\n",
    "output.seek(0)\n",
    "\n",
    "# Retrieve the results from the CSV writer and put them into a Pandas dataframe\n",
    "df_results = pd.read_csv(output, header=None)\n",
    "df_results.columns = columns\n",
    "\n",
    "# Format results\n",
    "df_results[[columns[1]]] = df_results[[columns[1]]].apply(lambda x: x.str.replace('\\n','')) # Remove CRLF from the article names\n",
    "\n",
    "df_results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
